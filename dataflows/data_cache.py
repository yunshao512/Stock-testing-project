#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®ç¼“å­˜ç®¡ç†å™¨
æé«˜æ•°æ®è·å–æ•ˆç‡ï¼Œå‡å°‘APIè°ƒç”¨
"""

import os
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from pathlib import Path


class DataCacheManager:
    """æ•°æ®ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, cache_dir: str = None, cache_hours: int = 1):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            cache_hours: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
        """
        self.cache_dir = cache_dir or os.path.join(
            os.path.dirname(__file__),
            '..',
            'data',
            'cache'
        )

        self.cache_hours = cache_hours

        # åˆ›å»ºç¼“å­˜ç›®å½•
        os.makedirs(self.cache_dir, exist_ok=True)

        print(f"âœ… æ•°æ®ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç¼“å­˜ç›®å½•: {self.cache_dir}")
        print(f"   æœ‰æ•ˆæœŸ: {cache_hours}å°æ—¶")

    def _get_cache_key(self, key_type: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        parts = [key_type]
        for k, v in sorted(kwargs.items()):
            parts.append(f"{k}={v}")
        return '_'.join(parts) + '.json'

    def _get_cache_path(self, cache_key: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.cache_dir, cache_key)

    def _is_cache_valid(self, cache_path: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if not os.path.exists(cache_path):
            return False

        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        file_time = datetime.fromtimestamp(os.path.getmtime(cache_path))
        expiry_time = datetime.now() - timedelta(hours=self.cache_hours)

        return file_time > expiry_time

    def get(self, key_type: str, **kwargs) -> Optional[Dict]:
        """
        ä»ç¼“å­˜è·å–æ•°æ®

        Args:
            key_type: ç¼“å­˜ç±»å‹ï¼ˆå¦‚ï¼šstock_data, historical_dataï¼‰
            **kwargs: ç¼“å­˜é”®å‚æ•°

        Returns:
            ç¼“å­˜æ•°æ®ï¼Œå¦‚æœæ— æ•ˆè¿”å›None
        """
        cache_key = self._get_cache_key(key_type, **kwargs)
        cache_path = self._get_cache_path(cache_key)

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
        if not self._is_cache_valid(cache_path):
            return None

        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if not data:
                return None

            print(f"âœ… [ç¼“å­˜] å‘½ä¸­: {cache_key}")
            return data

        except Exception as e:
            print(f"âŒ [ç¼“å­˜] è¯»å–å¤±è´¥: {e}")
            return None

    def set(self, key_type: str, data: Dict, **kwargs):
        """
        ä¿å­˜æ•°æ®åˆ°ç¼“å­˜

        Args:
            key_type: ç¼“å­˜ç±»å‹
            data: è¦ç¼“å­˜çš„æ•°æ®
            **kwargs: ç¼“å­˜é”®å‚æ•°
        """
        cache_key = self._get_cache_key(key_type, **kwargs)
        cache_path = self._get_cache_path(cache_key)

        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ [ç¼“å­˜] ä¿å­˜: {cache_key}")

        except Exception as e:
            print(f"âŒ [ç¼“å­˜] ä¿å­˜å¤±è´¥: {e}")

    def delete(self, key_type: str, **kwargs):
        """
        åˆ é™¤æŒ‡å®šç¼“å­˜

        Args:
            key_type: ç¼“å­˜ç±»å‹
            **kwargs: ç¼“å­˜é”®å‚æ•°
        """
        cache_key = self._get_cache_key(key_type, **kwargs)
        cache_path = self._get_cache_path(cache_key)

        if os.path.exists(cache_path):
            os.remove(cache_path)
            print(f"ğŸ—‘ï¸ [ç¼“å­˜] åˆ é™¤: {cache_key}")

    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        try:
            for filename in os.listdir(self.cache_dir):
                if filename.endswith('.json'):
                    file_path = os.path.join(self.cache_dir, filename)
                    os.remove(file_path)

            print(f"ğŸ—‘ï¸ [ç¼“å­˜] å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜")

        except Exception as e:
            print(f"âŒ [ç¼“å­˜] æ¸…ç©ºå¤±è´¥: {e}")

    def get_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_files': 0,
            'total_size': 0,
            'valid_files': 0,
            'expired_files': 0
        }

        try:
            now = datetime.now()
            expiry_time = now - timedelta(hours=self.cache_hours)

            for filename in os.listdir(self.cache_dir):
                if filename.endswith('.json'):
                    stats['total_files'] += 1

                    file_path = os.path.join(self.cache_dir, filename)
                    file_size = os.path.getsize(file_path)
                    stats['total_size'] += file_size

                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))

                    if file_time > expiry_time:
                        stats['valid_files'] += 1
                    else:
                        stats['expired_files'] += 1

        except Exception as e:
            print(f"âŒ [ç¼“å­˜] ç»Ÿè®¡å¤±è´¥: {e}")

        return stats

    def cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        try:
            now = datetime.now()
            expiry_time = now - timedelta(hours=self.cache_hours)

            cleaned = 0
            for filename in os.listdir(self.cache_dir):
                if filename.endswith('.json'):
                    file_path = os.path.join(self.cache_dir, filename)
                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))

                    if file_time <= expiry_time:
                        os.remove(file_path)
                        cleaned += 1

            if cleaned > 0:
                print(f"ğŸ—‘ï¸ [ç¼“å­˜] å·²æ¸…ç† {cleaned} ä¸ªè¿‡æœŸæ–‡ä»¶")
            else:
                print(f"âœ… [ç¼“å­˜] æ²¡æœ‰è¿‡æœŸæ–‡ä»¶")

        except Exception as e:
            print(f"âŒ [ç¼“å­˜] æ¸…ç†å¤±è´¥: {e}")


# å•ä¾‹æ¨¡å¼
_cache_instance = None

def get_cache(cache_dir: str = None, cache_hours: int = 1) -> DataCacheManager:
    """è·å–ç¼“å­˜ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _cache_instance

    if _cache_instance is None:
        _cache_instance = DataCacheManager(cache_dir, cache_hours)

    return _cache_instance


def test_cache():
    """æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨"""
    print("="*80)
    print("ğŸ§ª æµ‹è¯•æ•°æ®ç¼“å­˜ç®¡ç†å™¨")
    print("="*80)

    cache = get_cache(cache_hours=0.5)  # 30åˆ†é’Ÿè¿‡æœŸ

    print("\nğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
    stats = cache.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")

    print("\nğŸ’¾ æµ‹è¯•ç¼“å­˜æ“ä½œ:")
    test_data = {
        'symbol': '600519',
        'price': 1438.00,
        'timestamp': datetime.now().isoformat()
    }

    cache.set('stock_data', test_data, symbol='600519')
    cached_data = cache.get('stock_data', symbol='600519')

    if cached_data:
        print(f"âœ… ç¼“å­˜è¯»å–æˆåŠŸ: {cached_data['symbol']} = Â¥{cached_data['price']:.2f}")
    else:
        print(f"âŒ ç¼“å­˜è¯»å–å¤±è´¥")

    print("\nâœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_cache()
